{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfyZ8BtDFIKy7564rFH4OA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mounika-b-25/Traffic-Collision-Analysis-and-Flow-Simulation-in-Toronto-Using-Cellular-Automata-Models/blob/main/Project_rough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHraVu8G4Je6",
        "outputId": "fc2e629a-4a50-476f-ebd5-4f190287d69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the zip files**"
      ],
      "metadata": {
        "id": "EHbLqrzKY66R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# List of zip files\n",
        "zip_files = [\"/content/archive (1).zip\", \"/content/archive (2).zip\"]\n",
        "\n",
        "# Extract each file\n",
        "for zip_path in zip_files:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        extract_path = \"/content/extracted_\" + os.path.basename(zip_path).replace(\".zip\", \"\").replace(\" \", \"_\")\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "        zip_ref.extractall(extract_path)\n",
        "        print(f\"Extracted: {zip_path} to {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu-L9YRC_dpC",
        "outputId": "cb922818-e697-4e2e-af9b-b5bc19002639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted: /content/archive (1).zip to /content/extracted_archive_(1)\n",
            "Extracted: /content/archive (2).zip to /content/extracted_archive_(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries and Load the Data**"
      ],
      "metadata": {
        "id": "9sGZAmoHY-bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "traffic_df = pd.read_csv('/content/extracted_archive_(1)/Traffic_Collisions_Toronto_data.csv')\n",
        "ksi_df = pd.read_csv('/content/extracted_archive_(2)/KSI.csv')\n"
      ],
      "metadata": {
        "id": "jCvaolHJBmuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inspect the Data**"
      ],
      "metadata": {
        "id": "xxuVZfEuZFYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traffic dataset\n",
        "print(\"Traffic Collisions Dataset Info:\")\n",
        "print(traffic_df.shape)\n",
        "print(traffic_df.columns)\n",
        "print(traffic_df.head())\n",
        "\n",
        "# KSI dataset\n",
        "print(\"\\nKSI Dataset Info:\")\n",
        "print(ksi_df.shape)\n",
        "print(ksi_df.columns)\n",
        "print(ksi_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPSAmisoCbPl",
        "outputId": "73f14ad7-02a1-4fce-ccac-37fec59e1acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traffic Collisions Dataset Info:\n",
            "(499538, 19)\n",
            "Index(['X', 'Y', 'OBJECTID', 'EventUniqueId', 'OccurrenceDate', 'Month',\n",
            "       'Day_of_Week', 'Year', 'Hour', 'Division', 'Atom', 'Neighbourhood',\n",
            "       'Fatalities', 'Injury_Collisions', 'FTR_Collisions', 'PD_Collisions',\n",
            "       'Longitude', 'Latitude', 'ObjectId2'],\n",
            "      dtype='object')\n",
            "     X    Y  OBJECTID   EventUniqueId          OccurrenceDate     Month  \\\n",
            "0  0.0  0.0         1     GO-20141001  2014/02/07 05:00:00+00  February   \n",
            "1  0.0  0.0         2  GO-20141225593  2014/01/02 05:00:00+00   January   \n",
            "2  0.0  0.0         3  GO-20141260499  2014/01/01 05:00:00+00   January   \n",
            "3  0.0  0.0         4  GO-20141260663  2014/01/01 05:00:00+00   January   \n",
            "4  0.0  0.0         5  GO-20141261162  2014/01/01 05:00:00+00   January   \n",
            "\n",
            "  Day_of_Week  Year  Hour Division Atom Neighbourhood  Fatalities  \\\n",
            "0      Friday  2014    16      NSA  NSA           NSA           0   \n",
            "1    Thursday  2014     3      NSA  NSA           NSA           0   \n",
            "2   Wednesday  2014     2      NSA  NSA           NSA           0   \n",
            "3   Wednesday  2014     3      NSA  NSA           NSA           0   \n",
            "4   Wednesday  2014     5      NSA  NSA           NSA           0   \n",
            "\n",
            "  Injury_Collisions FTR_Collisions PD_Collisions  Longitude  Latitude  \\\n",
            "0                NO             NO           YES        0.0       0.0   \n",
            "1                NO            YES            NO        0.0       0.0   \n",
            "2               YES             NO            NO        0.0       0.0   \n",
            "3                NO             NO           YES        0.0       0.0   \n",
            "4               YES             NO            NO        0.0       0.0   \n",
            "\n",
            "   ObjectId2  \n",
            "0          1  \n",
            "1          2  \n",
            "2          3  \n",
            "3          4  \n",
            "4          5  \n",
            "\n",
            "KSI Dataset Info:\n",
            "(16860, 57)\n",
            "Index(['X', 'Y', 'INDEX_', 'ACCNUM', 'YEAR', 'DATE', 'TIME', 'HOUR', 'STREET1',\n",
            "       'STREET2', 'OFFSET', 'ROAD_CLASS', 'DISTRICT', 'WARDNUM', 'DIVISION',\n",
            "       'LATITUDE', 'LONGITUDE', 'LOCCOORD', 'ACCLOC', 'TRAFFCTL', 'VISIBILITY',\n",
            "       'LIGHT', 'RDSFCOND', 'ACCLASS', 'IMPACTYPE', 'INVTYPE', 'INVAGE',\n",
            "       'INJURY', 'FATAL_NO', 'INITDIR', 'VEHTYPE', 'MANOEUVER', 'DRIVACT',\n",
            "       'DRIVCOND', 'PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE', 'CYCACT',\n",
            "       'CYCCOND', 'PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
            "       'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
            "       'REDLIGHT', 'ALCOHOL', 'DISABILITY', 'POLICE_DIVISION', 'HOOD_ID',\n",
            "       'NEIGHBOURHOOD', 'ObjectId'],\n",
            "      dtype='object')\n",
            "              X             Y   INDEX_  ACCNUM  YEAR                    DATE  \\\n",
            "0 -8.844611e+06  5.412414e+06  3387730  892658  2006  2006/03/11 05:00:00+00   \n",
            "1 -8.844611e+06  5.412414e+06  3387731  892658  2006  2006/03/11 05:00:00+00   \n",
            "2 -8.816480e+06  5.434843e+06  3388101  892810  2006  2006/03/11 05:00:00+00   \n",
            "3 -8.816480e+06  5.434843e+06  3388102  892810  2006  2006/03/11 05:00:00+00   \n",
            "4 -8.822759e+06  5.424516e+06  3387793  892682  2006  2006/03/12 05:00:00+00   \n",
            "\n",
            "   TIME  HOUR          STREET1           STREET2  ... PASSENGER SPEEDING  \\\n",
            "0   852     8       BLOOR ST W       DUNDAS ST W  ...    <Null>   <Null>   \n",
            "1   852     8       BLOOR ST W       DUNDAS ST W  ...    <Null>   <Null>   \n",
            "2   915     9  MORNINGSIDE AVE    SHEPPARD AVE E  ...    <Null>   <Null>   \n",
            "3   915     9  MORNINGSIDE AVE    SHEPPARD AVE E  ...    <Null>   <Null>   \n",
            "4   240     2   EGLINTON AVE E  COMMONWEALTH AVE  ...    <Null>   <Null>   \n",
            "\n",
            "  AG_DRIV REDLIGHT ALCOHOL  DISABILITY  POLICE_DIVISION HOOD_ID  \\\n",
            "0     Yes   <Null>  <Null>      <Null>              D11      88   \n",
            "1     Yes   <Null>  <Null>      <Null>              D11      88   \n",
            "2     Yes      Yes  <Null>      <Null>              D42     131   \n",
            "3     Yes      Yes  <Null>      <Null>              D42     131   \n",
            "4  <Null>   <Null>     Yes      <Null>              D41     138   \n",
            "\n",
            "          NEIGHBOURHOOD ObjectId  \n",
            "0  High Park North (88)        1  \n",
            "1  High Park North (88)        2  \n",
            "2           Rouge (131)        3  \n",
            "3           Rouge (131)        4  \n",
            "4   Eglinton East (138)        5  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Clean the KSI Dataset**  \n",
        " - Dropped unused index/object columns.  \n",
        " - Parsed DATE into datetime and renamed to Date.  \n",
        " - Standardized column names (Latitude, Longitude, Neighbourhood, Police_Division).  \n",
        " - Cleaned the Fatalities column similarly to traffic_df."
      ],
      "metadata": {
        "id": "u5CJJKauZJo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "traffic_df = traffic_df.drop(columns=['OBJECTID', 'ObjectId2'], errors='ignore')\n",
        "\n",
        "# Convert 'OccurrenceDate' to datetime\n",
        "traffic_df['OccurrenceDate'] = pd.to_datetime(traffic_df['OccurrenceDate'], errors='coerce')\n",
        "\n",
        "# Rename key columns for consistency\n",
        "traffic_df = traffic_df.rename(columns={\n",
        "    'OccurrenceDate': 'Date',\n",
        "    'Longitude': 'Longitude',\n",
        "    'Latitude': 'Latitude',\n",
        "    'Neighbourhood': 'Neighbourhood',\n",
        "    'Division': 'Police_Division'\n",
        "})\n",
        "\n",
        "# Optional: Fill or flag missing values\n",
        "traffic_df['Fatalities'] = pd.to_numeric(traffic_df['Fatalities'], errors='coerce').fillna(0)\n",
        "\n",
        "# Display cleaned traffic_df\n",
        "print(\"\\nCleaned Traffic Dataset Sample:\")\n",
        "print(traffic_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnDPRbI8EQfr",
        "outputId": "466944b7-4140-4f99-c877-dc1c8ca71a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned Traffic Dataset Sample:\n",
            "     X    Y   EventUniqueId                      Date     Month Day_of_Week  \\\n",
            "0  0.0  0.0     GO-20141001 2014-02-07 05:00:00+00:00  February      Friday   \n",
            "1  0.0  0.0  GO-20141225593 2014-01-02 05:00:00+00:00   January    Thursday   \n",
            "2  0.0  0.0  GO-20141260499 2014-01-01 05:00:00+00:00   January   Wednesday   \n",
            "3  0.0  0.0  GO-20141260663 2014-01-01 05:00:00+00:00   January   Wednesday   \n",
            "4  0.0  0.0  GO-20141261162 2014-01-01 05:00:00+00:00   January   Wednesday   \n",
            "\n",
            "   Year  Hour Police_Division Atom Neighbourhood  Fatalities  \\\n",
            "0  2014    16             NSA  NSA           NSA           0   \n",
            "1  2014     3             NSA  NSA           NSA           0   \n",
            "2  2014     2             NSA  NSA           NSA           0   \n",
            "3  2014     3             NSA  NSA           NSA           0   \n",
            "4  2014     5             NSA  NSA           NSA           0   \n",
            "\n",
            "  Injury_Collisions FTR_Collisions PD_Collisions  Longitude  Latitude  \n",
            "0                NO             NO           YES        0.0       0.0  \n",
            "1                NO            YES            NO        0.0       0.0  \n",
            "2               YES             NO            NO        0.0       0.0  \n",
            "3                NO             NO           YES        0.0       0.0  \n",
            "4               YES             NO            NO        0.0       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Clean traffic_df**  \n",
        " - Column Names: The code now uses the Date column for datetime conversion (since your data contains Date instead of OccurrenceDate).  \n",
        " - Error Handling: If there were any non-date values in the Date column, they will be coerced to NaT (Not a Time).  \n",
        " - Data Cleaning: Placeholder values ('NSA') are replaced with NaN, and Fatalities are converted to numeric values.  \n",
        " - Duplicate Removal: Duplicates in the dataset are dropped.  \n",
        " - Extracting Month and Weekday: The Month and DayOfWeek columns are created for better analysis."
      ],
      "metadata": {
        "id": "obrb438pZNga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning and Preparation for KSI Dataset**"
      ],
      "metadata": {
        "id": "qn6xlNqgZmVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "ksi_df = ksi_df.drop(columns=['INDEX_', 'ObjectId'], errors='ignore')\n",
        "\n",
        "# Convert 'DATE' to datetime\n",
        "ksi_df['DATE'] = pd.to_datetime(ksi_df['DATE'], errors='coerce')\n",
        "\n",
        "# Rename key columns for consistency\n",
        "ksi_df = ksi_df.rename(columns={\n",
        "    'DATE': 'Date',\n",
        "    'LONGITUDE': 'Longitude',\n",
        "    'LATITUDE': 'Latitude',\n",
        "    'NEIGHBOURHOOD': 'Neighbourhood',\n",
        "    'POLICE_DIVISION': 'Police_Division',\n",
        "    'FATAL_NO': 'Fatalities'\n",
        "})\n",
        "\n",
        "# Optional: Fill or convert fatality values\n",
        "ksi_df['Fatalities'] = pd.to_numeric(ksi_df['Fatalities'], errors='coerce').fillna(0)\n",
        "\n",
        "# Display cleaned ksi_df\n",
        "print(\"\\nCleaned KSI Dataset Sample:\")\n",
        "print(ksi_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm4qjBnpE0Zb",
        "outputId": "80098a4c-2df7-4b52-99d9-1ded459ed091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned KSI Dataset Sample:\n",
            "              X             Y  ACCNUM  YEAR                      Date  TIME  \\\n",
            "0 -8.844611e+06  5.412414e+06  892658  2006 2006-03-11 05:00:00+00:00   852   \n",
            "1 -8.844611e+06  5.412414e+06  892658  2006 2006-03-11 05:00:00+00:00   852   \n",
            "2 -8.816480e+06  5.434843e+06  892810  2006 2006-03-11 05:00:00+00:00   915   \n",
            "3 -8.816480e+06  5.434843e+06  892810  2006 2006-03-11 05:00:00+00:00   915   \n",
            "4 -8.822759e+06  5.424516e+06  892682  2006 2006-03-12 05:00:00+00:00   240   \n",
            "\n",
            "   HOUR          STREET1           STREET2  OFFSET  ... EMERG_VEH PASSENGER  \\\n",
            "0     8       BLOOR ST W       DUNDAS ST W  <Null>  ...    <Null>    <Null>   \n",
            "1     8       BLOOR ST W       DUNDAS ST W  <Null>  ...    <Null>    <Null>   \n",
            "2     9  MORNINGSIDE AVE    SHEPPARD AVE E  <Null>  ...    <Null>    <Null>   \n",
            "3     9  MORNINGSIDE AVE    SHEPPARD AVE E  <Null>  ...    <Null>    <Null>   \n",
            "4     2   EGLINTON AVE E  COMMONWEALTH AVE  <Null>  ...    <Null>    <Null>   \n",
            "\n",
            "  SPEEDING AG_DRIV  REDLIGHT  ALCOHOL DISABILITY Police_Division HOOD_ID  \\\n",
            "0   <Null>     Yes    <Null>   <Null>     <Null>             D11      88   \n",
            "1   <Null>     Yes    <Null>   <Null>     <Null>             D11      88   \n",
            "2   <Null>     Yes       Yes   <Null>     <Null>             D42     131   \n",
            "3   <Null>     Yes       Yes   <Null>     <Null>             D42     131   \n",
            "4   <Null>  <Null>    <Null>      Yes     <Null>             D41     138   \n",
            "\n",
            "          Neighbourhood  \n",
            "0  High Park North (88)  \n",
            "1  High Park North (88)  \n",
            "2           Rouge (131)  \n",
            "3           Rouge (131)  \n",
            "4   Eglinton East (138)  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names\n",
        "print(traffic_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7QuHP4GE3ns",
        "outputId": "38e5faee-aca1-4b97-c09a-82412231deb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['X', 'Y', 'EventUniqueId', 'Date', 'Month', 'Day_of_Week', 'Year',\n",
            "       'Hour', 'Police_Division', 'Atom', 'Neighbourhood', 'Fatalities',\n",
            "       'Injury_Collisions', 'FTR_Collisions', 'PD_Collisions', 'Longitude',\n",
            "       'Latitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename key columns for consistency\n",
        "traffic_df = traffic_df.rename(columns={\n",
        "    'occurred_at': 'Date',\n",
        "    'Longitude': 'Longitude',\n",
        "    'Latitude': 'Latitude',\n",
        "    'Neighbourhood': 'Neighbourhood',\n",
        "    'Division': 'Police_Division'\n",
        "})\n"
      ],
      "metadata": {
        "id": "dGHqy10AGW2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'OccurrenceDate' exists before attempting to convert\n",
        "if 'OccurrenceDate' in traffic_df.columns:\n",
        "    traffic_df['OccurrenceDate'] = pd.to_datetime(traffic_df['OccurrenceDate'], errors='coerce')\n",
        "else:\n",
        "    print(\"'OccurrenceDate' column not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS-Ks5JAGikZ",
        "outputId": "fd2b0c5b-e7d9-4839-f6f4-136a085e7c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'OccurrenceDate' column not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning and Preparation for Traffic Dataset**"
      ],
      "metadata": {
        "id": "ovk590FEZxuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Drop unnecessary columns\n",
        "traffic_df = traffic_df.drop(columns=['OBJECTID', 'ObjectId2'], errors='ignore')\n",
        "\n",
        "# Convert 'Date' to datetime\n",
        "traffic_df['Date'] = pd.to_datetime(traffic_df['Date'], errors='coerce')\n",
        "\n",
        "# Rename key columns for consistency\n",
        "traffic_df = traffic_df.rename(columns={\n",
        "    'Longitude': 'Longitude',\n",
        "    'Latitude': 'Latitude',\n",
        "    'Neighbourhood': 'Neighbourhood',\n",
        "    'Division': 'Police_Division'\n",
        "})\n",
        "\n",
        "# Replace placeholder values with NaN (e.g., 'NSA' placeholder)\n",
        "traffic_df.replace('NSA', np.nan, inplace=True)\n",
        "\n",
        "# Convert Fatalities to numeric and fill missing with 0\n",
        "traffic_df['Fatalities'] = pd.to_numeric(traffic_df['Fatalities'], errors='coerce').fillna(0)\n",
        "\n",
        "# Drop duplicates\n",
        "traffic_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Optional: Extract month and weekday\n",
        "traffic_df['Month'] = traffic_df['Date'].dt.month_name()\n",
        "traffic_df['DayOfWeek'] = traffic_df['Date'].dt.day_name()\n",
        "\n",
        "# View cleaned traffic dataset\n",
        "print(\"\\nCleaned Traffic Dataset Sample:\")\n",
        "print(traffic_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBGHeuUuGlGq",
        "outputId": "105da667-1901-44a0-8029-3512a8bc00f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned Traffic Dataset Sample:\n",
            "     X    Y   EventUniqueId                      Date     Month Day_of_Week  \\\n",
            "0  0.0  0.0     GO-20141001 2014-02-07 05:00:00+00:00  February      Friday   \n",
            "1  0.0  0.0  GO-20141225593 2014-01-02 05:00:00+00:00   January    Thursday   \n",
            "2  0.0  0.0  GO-20141260499 2014-01-01 05:00:00+00:00   January   Wednesday   \n",
            "3  0.0  0.0  GO-20141260663 2014-01-01 05:00:00+00:00   January   Wednesday   \n",
            "4  0.0  0.0  GO-20141261162 2014-01-01 05:00:00+00:00   January   Wednesday   \n",
            "\n",
            "   Year  Hour Police_Division Atom Neighbourhood  Fatalities  \\\n",
            "0  2014    16             NaN  NaN           NaN           0   \n",
            "1  2014     3             NaN  NaN           NaN           0   \n",
            "2  2014     2             NaN  NaN           NaN           0   \n",
            "3  2014     3             NaN  NaN           NaN           0   \n",
            "4  2014     5             NaN  NaN           NaN           0   \n",
            "\n",
            "  Injury_Collisions FTR_Collisions PD_Collisions  Longitude  Latitude  \\\n",
            "0                NO             NO           YES        0.0       0.0   \n",
            "1                NO            YES            NO        0.0       0.0   \n",
            "2               YES             NO            NO        0.0       0.0   \n",
            "3                NO             NO           YES        0.0       0.0   \n",
            "4               YES             NO            NO        0.0       0.0   \n",
            "\n",
            "   DayOfWeek  \n",
            "0     Friday  \n",
            "1   Thursday  \n",
            "2  Wednesday  \n",
            "3  Wednesday  \n",
            "4  Wednesday  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check available columns to verify the exact column names\n",
        "print(\"\\nColumn Names in the KSI Dataset:\")\n",
        "print(ksi_df.columns)\n",
        "\n",
        "# If the 'DATE' column is found with different casing, let's inspect and rename it\n",
        "ksi_df.columns = ksi_df.columns.str.strip()  # Remove any leading/trailing spaces\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v922ybt5G8Zu",
        "outputId": "fdf967e5-0428-4682-8bee-7967e18cd59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Column Names in the KSI Dataset:\n",
            "Index(['X', 'Y', 'ACCNUM', 'YEAR', 'Date', 'TIME', 'HOUR', 'STREET1',\n",
            "       'STREET2', 'OFFSET', 'ROAD_CLASS', 'DISTRICT', 'WARDNUM', 'DIVISION',\n",
            "       'Latitude', 'Longitude', 'LOCCOORD', 'ACCLOC', 'TRAFFCTL', 'VISIBILITY',\n",
            "       'LIGHT', 'RDSFCOND', 'ACCLASS', 'IMPACTYPE', 'INVTYPE', 'INVAGE',\n",
            "       'INJURY', 'Fatalities', 'INITDIR', 'VEHTYPE', 'MANOEUVER', 'DRIVACT',\n",
            "       'DRIVCOND', 'PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE', 'CYCACT',\n",
            "       'CYCCOND', 'PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
            "       'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
            "       'REDLIGHT', 'ALCOHOL', 'DISABILITY', 'Police_Division', 'HOOD_ID',\n",
            "       'Neighbourhood'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Drop unnecessary columns\n",
        "ksi_df = ksi_df.drop(columns=['INDEX_', 'ObjectId'], errors='ignore')\n",
        "\n",
        "# Convert 'Date' to datetime\n",
        "ksi_df['Date'] = pd.to_datetime(ksi_df['Date'], errors='coerce')\n",
        "\n",
        "# Rename key columns for consistency\n",
        "ksi_df = ksi_df.rename(columns={\n",
        "    'Date': 'Date',\n",
        "    'Longitude': 'Longitude',\n",
        "    'Latitude': 'Latitude',\n",
        "    'Neighbourhood': 'Neighbourhood',\n",
        "    'Police_Division': 'Police_Division',\n",
        "    'Fatalities': 'Fatalities'\n",
        "})\n",
        "\n",
        "# Replace placeholder values with NaN\n",
        "ksi_df.replace('<Null>', np.nan, inplace=True)\n",
        "\n",
        "# Convert Fatalities to numeric and fill missing with 0\n",
        "ksi_df['Fatalities'] = pd.to_numeric(ksi_df['Fatalities'], errors='coerce').fillna(0)\n",
        "\n",
        "# Drop duplicates\n",
        "ksi_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Optional: Extract month and weekday\n",
        "ksi_df['Month'] = ksi_df['Date'].dt.month_name()\n",
        "ksi_df['DayOfWeek'] = ksi_df['Date'].dt.day_name()\n",
        "\n",
        "# View cleaned KSI dataset\n",
        "print(\"\\nCleaned KSI Dataset Sample:\")\n",
        "print(ksi_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRhwBH5ZH4WE",
        "outputId": "7a134d5e-4b0a-4053-c77b-f2ce0e7b74ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned KSI Dataset Sample:\n",
            "              X             Y  ACCNUM  YEAR                      Date  TIME  \\\n",
            "0 -8.844611e+06  5.412414e+06  892658  2006 2006-03-11 05:00:00+00:00   852   \n",
            "1 -8.844611e+06  5.412414e+06  892658  2006 2006-03-11 05:00:00+00:00   852   \n",
            "2 -8.816480e+06  5.434843e+06  892810  2006 2006-03-11 05:00:00+00:00   915   \n",
            "3 -8.816480e+06  5.434843e+06  892810  2006 2006-03-11 05:00:00+00:00   915   \n",
            "4 -8.822759e+06  5.424516e+06  892682  2006 2006-03-12 05:00:00+00:00   240   \n",
            "\n",
            "   HOUR          STREET1           STREET2 OFFSET  ... SPEEDING AG_DRIV  \\\n",
            "0     8       BLOOR ST W       DUNDAS ST W    NaN  ...      NaN     Yes   \n",
            "1     8       BLOOR ST W       DUNDAS ST W    NaN  ...      NaN     Yes   \n",
            "2     9  MORNINGSIDE AVE    SHEPPARD AVE E    NaN  ...      NaN     Yes   \n",
            "3     9  MORNINGSIDE AVE    SHEPPARD AVE E    NaN  ...      NaN     Yes   \n",
            "4     2   EGLINTON AVE E  COMMONWEALTH AVE    NaN  ...      NaN     NaN   \n",
            "\n",
            "  REDLIGHT ALCOHOL  DISABILITY  Police_Division HOOD_ID         Neighbourhood  \\\n",
            "0      NaN     NaN         NaN              D11      88  High Park North (88)   \n",
            "1      NaN     NaN         NaN              D11      88  High Park North (88)   \n",
            "2      Yes     NaN         NaN              D42     131           Rouge (131)   \n",
            "3      Yes     NaN         NaN              D42     131           Rouge (131)   \n",
            "4      NaN     Yes         NaN              D41     138   Eglinton East (138)   \n",
            "\n",
            "   Month DayOfWeek  \n",
            "0  March  Saturday  \n",
            "1  March  Saturday  \n",
            "2  March  Saturday  \n",
            "3  March  Saturday  \n",
            "4  March    Sunday  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Missing Values in Key Join Columns (Longitude, Latitude, Date, Police_Division)**"
      ],
      "metadata": {
        "id": "JWFnOBekzdBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the key columns for both datasets\n",
        "print(\"Missing values in Traffic dataset (join columns):\")\n",
        "print(traffic_df[['Longitude', 'Latitude', 'Date', 'Police_Division']].isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in KSI dataset (join columns):\")\n",
        "print(ksi_df[['Longitude', 'Latitude', 'Date', 'Police_Division']].isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4NI705RLSpf",
        "outputId": "244333ab-eefc-4e5d-a636-c422ae99f72b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in Traffic dataset (join columns):\n",
            "Longitude              0\n",
            "Latitude               0\n",
            "Date                   0\n",
            "Police_Division    69997\n",
            "dtype: int64\n",
            "\n",
            "Missing values in KSI dataset (join columns):\n",
            "Longitude          0\n",
            "Latitude           0\n",
            "Date               0\n",
            "Police_Division    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values of join columns in both datasets\n",
        "print(\"Unique 'Longitude' values in Traffic dataset:\")\n",
        "print(traffic_df['Longitude'].unique())\n",
        "\n",
        "print(\"\\nUnique 'Longitude' values in KSI dataset:\")\n",
        "print(ksi_df['Longitude'].unique())\n",
        "\n",
        "# Repeat for other join columns (Latitude, Date, Police_Division)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OBv9WIVMsnY",
        "outputId": "b74e57e1-a6ef-453f-e4a5-46eb9ba87db4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique 'Longitude' values in Traffic dataset:\n",
            "[  0.         -79.13288116 -79.13217549 ... -79.64239754 -79.63592147\n",
            " -79.63917958]\n",
            "\n",
            "Unique 'Longitude' values in KSI dataset:\n",
            "[-79.45249  -79.199786 -79.25619  ... -79.410084 -79.238926 -79.232021]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing: Rounding Coordinates, Formatting Dates, and Cleaning Police Division Names**"
      ],
      "metadata": {
        "id": "hvVIPPOQz1iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traffic_df['Police_Division'] = traffic_df['Police_Division'].fillna('Unknown')\n"
      ],
      "metadata": {
        "id": "kIydfbP0M3Qw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traffic_df = traffic_df[traffic_df['Longitude'] != 0.0]\n"
      ],
      "metadata": {
        "id": "6kTqZUFNNFDe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traffic_df['Longitude'] = traffic_df['Longitude'].round(4)\n",
        "traffic_df['Latitude'] = traffic_df['Latitude'].round(4)\n",
        "ksi_df['Longitude'] = ksi_df['Longitude'].round(4)\n",
        "ksi_df['Latitude'] = ksi_df['Latitude'].round(4)\n"
      ],
      "metadata": {
        "id": "Kpus8cEiNKX6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traffic_df['Date'] = pd.to_datetime(traffic_df['Date']).dt.date\n",
        "ksi_df['Date'] = pd.to_datetime(ksi_df['Date']).dt.date\n"
      ],
      "metadata": {
        "id": "l9ie3TVHN9jV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traffic_df['Police_Division'] = traffic_df['Police_Division'].astype(str).str.lower().str.strip()\n",
        "ksi_df['Police_Division'] = ksi_df['Police_Division'].astype(str).str.lower().str.strip()\n"
      ],
      "metadata": {
        "id": "YiQbCvMVN_pf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ksi_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGm4tbScO14h",
        "outputId": "1c79a662-644f-488d-b828-7f1a476c13ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['X', 'Y', 'ACCNUM', 'YEAR', 'Date', 'TIME', 'HOUR', 'STREET1',\n",
            "       'STREET2', 'OFFSET', 'ROAD_CLASS', 'DISTRICT', 'WARDNUM', 'DIVISION',\n",
            "       'Latitude', 'Longitude', 'LOCCOORD', 'ACCLOC', 'TRAFFCTL', 'VISIBILITY',\n",
            "       'LIGHT', 'RDSFCOND', 'ACCLASS', 'IMPACTYPE', 'INVTYPE', 'INVAGE',\n",
            "       'INJURY', 'Fatalities', 'INITDIR', 'VEHTYPE', 'MANOEUVER', 'DRIVACT',\n",
            "       'DRIVCOND', 'PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE', 'CYCACT',\n",
            "       'CYCCOND', 'PEDESTRIAN', 'CYCLIST', 'AUTOMOBILE', 'MOTORCYCLE', 'TRUCK',\n",
            "       'TRSN_CITY_VEH', 'EMERG_VEH', 'PASSENGER', 'SPEEDING', 'AG_DRIV',\n",
            "       'REDLIGHT', 'ALCOHOL', 'DISABILITY', 'Police_Division', 'HOOD_ID',\n",
            "       'Neighbourhood', 'Month', 'DayOfWeek'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are completely empty\n",
        "final_df = final_df.dropna(axis=1, how='all')\n"
      ],
      "metadata": {
        "id": "ff1lEVe_QB69"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['INJURY', 'INITDIR', 'VEHTYPE', 'MANOEUVER', 'DRIVACT', 'DRIVCOND']:\n",
        "    final_df[col] = final_df[col].fillna('Unknown')\n"
      ],
      "metadata": {
        "id": "aKkrUuM8QJTi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Analysis: Unique Non-Null Values in Fully and Partially Missing Columns**"
      ],
      "metadata": {
        "id": "W2YYQSBX0Ele"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully missing columns — check unique non-null values\n",
        "fully_empty_cols = [\n",
        "    'PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE', 'CYCACT', 'CYCCOND',\n",
        "    'MOTORCYCLE', 'TRUCK', 'TRSN_CITY_VEH', 'EMERG_VEH',\n",
        "    'REDLIGHT', 'ALCOHOL', 'DISABILITY'\n",
        "]\n",
        "\n",
        "# Partially missing columns\n",
        "partially_empty_cols = ['PEDESTRIAN', 'CYCLIST', 'PASSENGER', 'SPEEDING',\n",
        "                        'ALCOHOL', 'DISABILITY', 'REDLIGHT', 'TRSN_CITY_VEH', 'EMERG_VEH',\n",
        "                        'MOTORCYCLE', 'TRUCK']\n",
        "\n",
        "# Get unique non-null values in each column\n",
        "for col in fully_empty_cols + partially_empty_cols:\n",
        "    print(f\"Unique values in column '{col}':\")\n",
        "    print(final_df[col].dropna().unique())\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSb_roPaQNSP",
        "outputId": "03f5133c-9d2f-4823-b675-8f3b8d061627"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in column 'PEDTYPE':\n",
            "['Vehicle is going straight thru inter.while ped cross with ROW'\n",
            " 'Vehicle turns left while ped crosses with ROW at inter.'\n",
            " 'Vehicle is going straight thru inter.while ped cross without ROW'\n",
            " 'Vehicle hits the pedestrian walking or running out from between parked vehicles at mid-block'\n",
            " 'Pedestrian hit at mid-block' 'Pedestrian hit on sidewalk or shoulder'\n",
            " 'Vehicle turns right while ped crosses without ROW at inter.'\n",
            " 'Vehicle turns left while ped crosses without ROW at inter.'\n",
            " 'Vehicle turns right while ped crosses with ROW at inter.'\n",
            " 'Pedestrian hit a PXO/ped. Mid-block signal'\n",
            " 'Vehicle is reversing and hits pedestrian'\n",
            " 'Pedestrian hit at private driveway' 'Other / Undefined' 'Unknown'\n",
            " 'Pedestrian involved in a collision with transit vehicle anywhere along roadway']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'PEDACT':\n",
            "['Crossing with right of way' 'Crossing without right of way'\n",
            " 'Crossing, no Traffic Control' 'Running onto Roadway'\n",
            " 'On Sidewalk or Shoulder' 'Crossing marked crosswalk without ROW'\n",
            " 'Walking on Roadway with Traffic' 'Crossing, Pedestrian Crossover'\n",
            " 'Other' 'Pushing/Working on Vehicle' 'Person Getting on/off Vehicle'\n",
            " 'Walking on Roadway Against Traffic' 'Playing or Working on Highway']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'PEDCOND':\n",
            "['Normal' 'Inattentive' 'Unknown' 'Had Been Drinking'\n",
            " 'Ability Impaired, Alcohol' 'Medical or Physical Disability'\n",
            " 'Ability Impaired, Drugs' 'Other' 'Ability Impaired, Alcohol Over .80']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'CYCLISTYPE':\n",
            "['Motorist without ROW drives into path of cyclist at inter, lnwy, dwy-Driver not turn.'\n",
            " 'Cyclist without ROW rides into path of motorist at inter, lnwy, dwy-Cyclist not turn.'\n",
            " 'Cyclist turned left across motorists path.'\n",
            " 'Cyclist and Driver travelling in same direction. One vehicle rear-ended the other.'\n",
            " 'Motorist turned left across cyclists path.'\n",
            " 'Cyclist turns right across motorists path'\n",
            " 'Motorist turning right on red at signalized intersection strikes cyclist.'\n",
            " 'Motorist turning right on green or amber at signalized intersection strikes cyclist.'\n",
            " 'Motorist turns right at non-signal Inter.(stop, yield, no cont.,and dwy) and strikes cyclist.'\n",
            " 'Cyclist and Driver travelling in same direction. One vehicle sideswipes the other.'\n",
            " 'Insufficient information (to determine cyclist crash type).'\n",
            " 'Cyclist strikes pedestrian.' 'Cyclist struck opened vehicle door'\n",
            " 'Motorist makes u-turn in-front of cyclist.'\n",
            " 'Cyclist makes u-turn in-front of driver.'\n",
            " 'Cyclist falls off bike - no contact with motorist.'\n",
            " 'Cyclist rode off sidewalk into road at midblock.']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'CYCACT':\n",
            "['Driving Properly' 'Disobeyed Traffic Control' 'Improper Turn'\n",
            " 'Failed to Yield Right of Way' 'Other' 'Improper Passing'\n",
            " 'Improper Lane Change' 'Lost control' 'Speed too Fast For Condition']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'CYCCOND':\n",
            "['Unknown' 'Normal' 'Inattentive' 'Other' 'Had Been Drinking'\n",
            " 'Medical or Physical Disability']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'MOTORCYCLE':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'TRUCK':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'TRSN_CITY_VEH':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'EMERG_VEH':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'REDLIGHT':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'ALCOHOL':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'DISABILITY':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'PEDESTRIAN':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'CYCLIST':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'PASSENGER':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'SPEEDING':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'ALCOHOL':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'DISABILITY':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'REDLIGHT':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'TRSN_CITY_VEH':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'EMERG_VEH':\n",
            "['No' 'Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'MOTORCYCLE':\n",
            "['Yes']\n",
            "--------------------------------------------------\n",
            "Unique values in column 'TRUCK':\n",
            "['Yes']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "condition_cols = ['PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE', 'CYCACT', 'CYCCOND']\n",
        "for col in condition_cols:\n",
        "    final_df[col] = final_df[col].fillna('Not Involved')\n"
      ],
      "metadata": {
        "id": "oBZYH7apRxy2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = ['ALCOHOL', 'DISABILITY', 'REDLIGHT', 'TRSN_CITY_VEH', 'EMERG_VEH',\n",
        "               'PEDESTRIAN', 'CYCLIST', 'PASSENGER', 'SPEEDING']\n",
        "\n",
        "for col in binary_cols:\n",
        "    final_df[col] = final_df[col].fillna('No')\n"
      ],
      "metadata": {
        "id": "xx9Y2RFBShhe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vehicle_cols = ['MOTORCYCLE', 'TRUCK']\n",
        "for col in vehicle_cols:\n",
        "    final_df[col] = final_df[col].fillna('No')\n"
      ],
      "metadata": {
        "id": "gbrEx6DUSi_v"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.dtypes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "7RZVhIqnSkiJ",
        "outputId": "e0a54643-9d4a-4dad-ee3e-57a9c1f0e754"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "X                  float64\n",
              "Y                  float64\n",
              "EventUniqueId       object\n",
              "Date                object\n",
              "Month               object\n",
              "                    ...   \n",
              "Police_Division     object\n",
              "HOOD_ID              int64\n",
              "Neighbourhood       object\n",
              "Month               object\n",
              "DayOfWeek           object\n",
              "Length: 79, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EventUniqueId</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Police_Division</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HOOD_ID</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neighbourhood</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DayOfWeek</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = ['ALCOHOL', 'DISABILITY', 'REDLIGHT', 'TRSN_CITY_VEH', 'EMERG_VEH',\n",
        "               'PEDESTRIAN', 'CYCLIST', 'PASSENGER', 'SPEEDING', 'MOTORCYCLE', 'TRUCK']\n",
        "\n",
        "for col in binary_cols:\n",
        "    final_df[col] = final_df[col].map({'Yes': 1, 'No': 0})\n"
      ],
      "metadata": {
        "id": "MBq07JyMSr5R"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column Removal: Dropping Empty, Zero-Only, and 'Not Involved'-Dominated Features**  \n",
        "- **Columns with Missing Data (OFFSET):**  \n",
        " - If a column has no values (completely empty), it doesn't provide any meaningful information for your analysis or modeling. The column OFFSET in your case might be empty, and if it has no value, keeping it in the dataset could add unnecessary noise or complexity without contributing to your analysis.  \n",
        "- ** Columns with All Zero Values (Fatalities, MOTORCYCLE, TRUCK, etc.):**  \n",
        " - If a column consists of only one value (e.g., all zeros), it doesn’t provide variability, which is essential for modeling or analysis. For example, if the MOTORCYCLE and TRUCK columns have only 'Yes' or zeros, it won't add much value because the column doesn't have any variation.  \n",
        " - In this case, if these columns are all filled with zeros or have a constant value across all rows, they won’t help in distinguishing data points and may just add redundancy to the analysis.  \n",
        "- **Columns with Irrelevant Data (PEDTYPE, PEDACT, etc.):**  \n",
        " - If columns like PEDTYPE, PEDACT, and CYCLISTYPE are filled with 'Not Involved' or irrelevant data for your analysis, they may not contribute meaningful insights. Dropping these columns can help to focus on the more relevant variables and simplify the dataset, reducing noise and making it easier to analyze.  \n",
        " - For example, if most of the data is labeled 'Not Involved', there’s little to no variation in those columns, and they won’t help in differentiating or analyzing the dataset.  \n",
        "- **Improving Model Performance:**  \n",
        " - In some cases, columns that don't add any value might negatively affect the performance of machine learning models by introducing unnecessary complexity and increasing the risk of overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "edZyEbsG0Xpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lists of columns to drop\n",
        "empty_cols = ['OFFSET']\n",
        "zero_cols = ['Fatalities', 'MOTORCYCLE', 'TRUCK', 'TRSN_CITY_VEH', 'REDLIGHT']\n",
        "uninvolved_cols = ['PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE']\n",
        "\n",
        "# Combine all\n",
        "columns_to_drop = empty_cols + zero_cols + uninvolved_cols\n",
        "\n",
        "# Drop from the DataFrame\n",
        "final_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "# Show what was dropped\n",
        "print(\"Dropped columns:\", columns_to_drop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPxSyUfKUtdy",
        "outputId": "7d1f71fa-9b14-468f-a24c-f82cac3e6874"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped columns: ['OFFSET', 'Fatalities', 'MOTORCYCLE', 'TRUCK', 'TRSN_CITY_VEH', 'REDLIGHT', 'PEDTYPE', 'PEDACT', 'PEDCOND', 'CYCLISTYPE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If the column contains missing data or has no values: It's pointless to keep empty columns.  \n",
        "- If the column doesn't contribute meaningful information: Columns that have constant values or that do not vary across data points can be safely removed.\n",
        "- If the column contains irrelevant or non-informative data: If it's filled with repeated, uninformative values like \"Not Involved\" or \"Unknown\", it's better to drop those columns to focus on more meaningful ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "dRqyYfwH11yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned DataFrame to a new CSV file\n",
        "final_df.to_csv('/content/drive/MyDrive/MRP/cleaned_data.csv', index=False)\n",
        "\n",
        "# Confirm the file has been saved\n",
        "print(\"Cleaned dataset saved as 'cleaned_data.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTGwragLWFOn",
        "outputId": "0fd019a7-3a0b-420b-9e1a-ff8713f4b953"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved as 'cleaned_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHx2OWxpWMqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}